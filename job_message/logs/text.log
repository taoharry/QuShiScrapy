2020-03-17 22:33:55 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: job_message)
2020-03-17 22:33:55 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-03-17 22:33:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'job_message',
 'CONCURRENT_REQUESTS': 4,
 'CONCURRENT_REQUESTS_PER_IP': 1,
 'LOG_FILE': 'E:\\pachong\\job_message\\logs/text.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'job_message.spiders',
 'SPIDER_MODULES': ['job_message.spiders']}
2020-03-17 22:33:55 [scrapy.extensions.telnet] INFO: Telnet Password: ba0acf33fdf4bdc9
2020-03-17 22:33:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-17 22:33:55 [boss] INFO: Boss webdrive start
2020-03-17 22:34:09 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: job_message)
2020-03-17 22:34:09 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-03-17 22:34:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'job_message',
 'CONCURRENT_REQUESTS': 4,
 'CONCURRENT_REQUESTS_PER_IP': 2,
 'LOG_FILE': 'E:\\pachong\\job_message\\logs/text.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'job_message.spiders',
 'SPIDER_MODULES': ['job_message.spiders']}
2020-03-17 22:34:09 [scrapy.extensions.telnet] INFO: Telnet Password: 93ab742e48520e38
2020-03-17 22:34:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-17 22:34:09 [boss] INFO: Boss webdrive start
2020-03-17 22:34:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'job_message.middle.user_agent.UserAgentMid',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'job_message.middlewares.JsMiddleware']
2020-03-17 22:34:15 [twisted] CRITICAL: Unhandled error in Deferred:
2020-03-17 22:34:15 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "E:\pachong\scripy_venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\crawler.py", line 89, in crawl
    self.engine = self._create_engine()
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\crawler.py", line 103, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\core\scraper.py", line 69, in __init__
    self.spidermw = SpiderMiddlewareManager.from_crawler(crawler)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\middleware.py", line 35, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\utils\misc.py", line 146, in create_instance
    return objcls.from_crawler(crawler, *args, **kwargs)
  File "E:\pachong\job_message\job_message\middle\spider_stats.py", line 17, in from_crawler
    return cls(crawler.stats)
  File "E:\pachong\job_message\job_message\middle\spider_stats.py", line 11, in __init__
    self.stats.set('request_total_url')
AttributeError: 'MemoryStatsCollector' object has no attribute 'set'
2020-03-17 22:34:55 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: job_message)
2020-03-17 22:34:55 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-03-17 22:34:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'job_message',
 'CONCURRENT_REQUESTS': 4,
 'CONCURRENT_REQUESTS_PER_IP': 2,
 'LOG_FILE': 'E:\\pachong\\job_message\\logs/text.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'job_message.spiders',
 'SPIDER_MODULES': ['job_message.spiders']}
2020-03-17 22:34:56 [scrapy.extensions.telnet] INFO: Telnet Password: e51b200f28912e89
2020-03-17 22:34:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-17 22:34:56 [boss] INFO: Boss webdrive start
2020-03-17 22:35:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'job_message.middle.user_agent.UserAgentMid',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'job_message.middlewares.JsMiddleware']
2020-03-17 22:40:38 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: job_message)
2020-03-17 22:40:38 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-03-17 22:40:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'job_message',
 'CONCURRENT_REQUESTS': 4,
 'CONCURRENT_REQUESTS_PER_IP': 1,
 'LOG_FILE': 'E:\\pachong\\job_message\\logs/text.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'job_message.spiders',
 'SPIDER_MODULES': ['job_message.spiders']}
2020-03-17 22:40:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'job_message.middle.spider_stats.SpiderStatsMid']
2020-03-17 22:40:38 [boss] INFO: Boss webdrive start
2020-03-17 22:40:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'job_message.middle.user_agent.UserAgentMid',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'job_message.middlewares.JsMiddleware']
2020-03-17 22:40:43 [twisted] CRITICAL: Unhandled error in Deferred:
2020-03-17 22:40:43 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "E:\pachong\scripy_venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\crawler.py", line 89, in crawl
    self.engine = self._create_engine()
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\crawler.py", line 103, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\core\scraper.py", line 69, in __init__
    self.spidermw = SpiderMiddlewareManager.from_crawler(crawler)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\middleware.py", line 35, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\utils\misc.py", line 146, in create_instance
    return objcls.from_crawler(crawler, *args, **kwargs)
  File "E:\pachong\job_message\job_message\middle\spider_mid.py", line 11, in from_crawler
    return cls(crawler.settings)
TypeError: SpiderMid() takes no arguments
2020-03-17 22:42:21 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: job_message)
2020-03-17 22:42:21 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-03-17 22:42:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'job_message',
 'CONCURRENT_REQUESTS': 4,
 'CONCURRENT_REQUESTS_PER_IP': 3,
 'LOG_FILE': 'E:\\pachong\\job_message\\logs/text.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'job_message.spiders',
 'SPIDER_MODULES': ['job_message.spiders']}
2020-03-17 22:42:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'job_message.middle.spider_stats.SpiderStatsMid']
2020-03-17 22:42:21 [boss] INFO: Boss webdrive start
2020-03-17 22:42:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'job_message.middle.user_agent.UserAgentMid',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'job_message.middlewares.JsMiddleware']
2020-03-17 22:42:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'job_message.middle.spider_mid.SpiderMid',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-17 22:42:27 [scrapy.middleware] INFO: Enabled item pipelines:
['job_message.pipelines.MysqlPoolInsertPipeline']
2020-03-17 22:42:27 [scrapy.core.engine] INFO: Spider opened
2020-03-17 22:42:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-17 22:42:27 [py.warnings] WARNING: E:\pachong\scripy_venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.zhipin.com in allowed_domains.
  warnings.warn(message, URLWarning)

2020-03-17 22:42:27 [boss] INFO: Boss crawl start
2020-03-17 22:42:27 [boss] INFO: Boss page:1
2020-03-17 22:42:27 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=1&ka=page-1
2020-03-17 22:42:27 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "E:\pachong\job_message\job_message\middle\spider_mid.py", line 17, in process_start_requests
    self.stats.inc_value('request_total_url')
AttributeError: 'SpiderMid' object has no attribute 'stats'
2020-03-17 22:42:27 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-17 22:42:27 [boss] INFO: Boss webdrive closed
2020-03-17 22:42:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.018989,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 17, 14, 42, 27, 94564),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'log_count/WARNING': 1,
 'start_time': datetime.datetime(2020, 3, 17, 14, 42, 27, 75575)}
2020-03-17 22:42:30 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-17 22:42:49 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: job_message)
2020-03-17 22:42:49 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-03-17 22:42:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'job_message',
 'CONCURRENT_REQUESTS': 4,
 'CONCURRENT_REQUESTS_PER_IP': 3,
 'LOG_FILE': 'E:\\pachong\\job_message\\logs/text.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'job_message.spiders',
 'SPIDER_MODULES': ['job_message.spiders']}
2020-03-17 22:42:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'job_message.middle.spider_stats.SpiderStatsMid']
2020-03-17 22:42:49 [boss] INFO: Boss webdrive start
2020-03-17 22:42:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'job_message.middle.user_agent.UserAgentMid',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'job_message.middlewares.JsMiddleware']
2020-03-17 22:42:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'job_message.middle.spider_mid.SpiderMid',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-17 22:42:55 [scrapy.middleware] INFO: Enabled item pipelines:
['job_message.pipelines.MysqlPoolInsertPipeline']
2020-03-17 22:42:55 [scrapy.core.engine] INFO: Spider opened
2020-03-17 22:42:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-17 22:42:55 [py.warnings] WARNING: E:\pachong\scripy_venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.zhipin.com in allowed_domains.
  warnings.warn(message, URLWarning)

2020-03-17 22:42:55 [boss] INFO: Boss crawl start
2020-03-17 22:42:55 [boss] INFO: Boss page:1
2020-03-17 22:42:55 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=1&ka=page-1
2020-03-17 22:42:55 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "E:\pachong\scripy_venv\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "E:\pachong\job_message\job_message\middle\spider_mid.py", line 24, in process_start_requests
    self.stats.inc_value('request_total_url')
AttributeError: 'SpiderMid' object has no attribute 'stats'
2020-03-17 22:42:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-17 22:42:55 [boss] INFO: Boss webdrive closed
2020-03-17 22:42:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.011993,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 17, 14, 42, 55, 62328),
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'log_count/WARNING': 1,
 'start_time': datetime.datetime(2020, 3, 17, 14, 42, 55, 50335)}
2020-03-17 22:42:57 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-17 22:43:15 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: job_message)
2020-03-17 22:43:15 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-03-17 22:43:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'job_message',
 'CONCURRENT_REQUESTS': 4,
 'CONCURRENT_REQUESTS_PER_IP': 3,
 'LOG_FILE': 'E:\\pachong\\job_message\\logs/text.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'job_message.spiders',
 'SPIDER_MODULES': ['job_message.spiders']}
2020-03-17 22:43:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'job_message.middle.spider_stats.SpiderStatsMid']
2020-03-17 22:43:15 [boss] INFO: Boss webdrive start
2020-03-17 22:43:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'job_message.middle.user_agent.UserAgentMid',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'job_message.middlewares.JsMiddleware']
2020-03-17 22:43:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-17 22:43:21 [scrapy.middleware] INFO: Enabled item pipelines:
['job_message.pipelines.MysqlPoolInsertPipeline']
2020-03-17 22:43:21 [scrapy.core.engine] INFO: Spider opened
2020-03-17 22:43:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-17 22:43:21 [py.warnings] WARNING: E:\pachong\scripy_venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://www.zhipin.com in allowed_domains.
  warnings.warn(message, URLWarning)

2020-03-17 22:43:21 [boss] INFO: Boss crawl start
2020-03-17 22:43:21 [boss] INFO: Boss page:1
2020-03-17 22:43:21 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=1&ka=page-1
2020-03-17 22:43:22 [boss] INFO: Boss page:2
2020-03-17 22:43:22 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=2&ka=page-2
2020-03-17 22:43:27 [boss] INFO: Boss page:3
2020-03-17 22:43:27 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=3&ka=page-3
2020-03-17 22:43:29 [boss] INFO: Boss page:4
2020-03-17 22:43:29 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=4&ka=page-4
2020-03-17 22:43:31 [boss] INFO: Boss page:5
2020-03-17 22:43:31 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=5&ka=page-5
2020-03-17 22:43:38 [boss] INFO: Boss page:6
2020-03-17 22:43:38 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=6&ka=page-6
2020-03-17 22:43:44 [boss] INFO: Boss page:7
2020-03-17 22:43:44 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=7&ka=page-7
2020-03-17 22:43:50 [boss] INFO: Boss page:8
2020-03-17 22:43:50 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=8&ka=page-8
2020-03-17 22:44:01 [boss] INFO: Boss page:9
2020-03-17 22:44:01 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=9&ka=page-9
2020-03-17 22:44:12 [boss] INFO: Boss page:10
2020-03-17 22:44:12 [boss] INFO: start url :https://www.zhipin.com/c101010100/y_6/?query=python%E7%88%AC%E8%99%AB%E5%B7%A5%E7%A8%8B%E5%B8%88&page=10&ka=page-10
2020-03-17 22:44:35 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 10 pages/min), scraped 35 items (at 35 items/min)
2020-03-17 22:45:35 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 80 items (at 45 items/min)
2020-03-17 22:46:35 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 121 items (at 41 items/min)
2020-03-17 22:47:33 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 162 items (at 41 items/min)
2020-03-17 22:48:36 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 207 items (at 45 items/min)
2020-03-17 22:49:34 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 247 items (at 40 items/min)
2020-03-17 22:50:28 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 285 items (at 38 items/min)
2020-03-17 22:50:50 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-17 22:50:50 [boss] INFO: Boss webdrive closed
2020-03-17 22:50:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3743,
 'downloader/request_count': 10,
 'downloader/request_method_count/GET': 10,
 'downloader/response_bytes': 2597590,
 'downloader/response_count': 10,
 'downloader/response_status_count/200': 10,
 'elapsed_time_seconds': 449.153173,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 17, 14, 50, 50, 259449),
 'item_scraped_count': 299,
 'log_count/INFO': 38,
 'log_count/WARNING': 1,
 'response_received_count': 10,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2020, 3, 17, 14, 43, 21, 106276)}
2020-03-17 22:50:52 [scrapy.core.engine] INFO: Spider closed (finished)
